<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <style>
    .carousel-container {
      overflow: hidden;
    }
    /* Force each carousel item to take up the full width, overriding JS inline styles */
    .carousel .item {
      flex-basis: 100% !important;
      flex-grow: 0 !important;
      flex-shrink: 0 !important;
    }
    .carousel .item img {
      width: 100%;
      height: auto;
      object-fit: contain;
    }
  </style>

  <title>Fine-grained Image Quality Assessment for Perceptual Image Restoration</title>
  <link href="https://fonts.googleapis.com/css2?family=Google+Sans|Noto+Sans|Castoro&display=swap"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body class="bg-gradient">  <!-- 选择渐变背景；若想用纯色，可改为 bg-solid -->


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              Fine-grained Image Quality Assessment for Perceptual Image Restoration
            </h1>
            <!-- 新增：AAAI 2026 接收徽章 -->
            <div class="acceptance-badge">
              <span class="tag is-medium is-info is-light">
                <span class="icon"><i class="fas fa-award"></i></span>
                <span>AAAI 2026</span>
              </span>
            </div>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://github.com/sxfly99" target="_blank">Xiangfei Sheng</a><sup>1,*,</sup>
              </span>
              <span class="author-block">
                <a href="https://github.com/pxf0429" target="_blank">Xiaofeng Pan</a><sup>1,*</sup>,
              </span>
              <span class="author-block">
                <a href="https://github.com/yzc-ippl" target="_blank">Zhichao Yang</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://faculty.xidian.edu.cn/cpf/" target="_blank">Pengfei Chen</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://web.xidian.edu.cn/ldli/" target="_blank">Leida Li</a><sup>1,2†</sup>
              </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>School of Artificial Intelligence, Xidian University</span>
                    <span class="author-block"><sup>2</sup>State Key Lab. of Electromechanical Integrated Manufacturing of High-Performance Electronic Equipments,Xidian University</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Equal Contribution, <sup>†</sup>Corresponding Author</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2508.14475.pdf" target="_blank"
                           class="external-link button is-normal is-rounded btn-paper">
                          <span class="icon">
                            <i class="fas fa-file-pdf"></i>
                          </span>
                          <span>Paper</span>
                        </a>
                      </span>

                      <!-- Github link -->
                      <span class="link-block">
                        <a href="https://github.com/sxfly99/FGResQ" target="_blank"
                           class="external-link button is-normal is-rounded btn-code">
                          <span class="icon">
                            <i class="fab fa-github"></i>
                          </span>
                          <span>Code</span>
                        </a>
                      </span>

                      <!-- ArXiv abstract Link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/2508.14475" target="_blank"
                           class="external-link button is-normal is-rounded btn-arxiv">
                          <span class="icon">
                            <i class="ai ai-arxiv"></i>
                          </span>
                          <span>arXiv</span>
                        </a>
                      </span>

                      <!-- Dataset Link-->
                      <span class="link-block">
                        <a href="https://sxfly99.github.io/FGResQ-Homepage/" target="_blank"
                           class="external-link button is-normal is-rounded btn-data">
                          <span class="icon">
                            <i class="fas fa-database"></i>
                          </span>
                          <span>Dataset (Coming Soon)</span>
                        </a>
                      </span>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
  </div>
</section>


<!-- Teaser video-->

<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 section-title">
          <span class="icon is-small"><i class="fas fa-file-alt"></i></span>
          <span>Abstract</span>
        </h2>
        <div class="content has-text-justified">
          <p>
          Recent years have witnessed remarkable achievements in perceptual image restoration (IR), creating an urgent demand for accurate image quality assessment (IQA), which is essential for both performance comparison and algorithm optimization. Unfortunately, the existing IQA metrics exhibit inherent weakness for IR task, particularly when distinguishing fine-grained quality differences among restored images. To address this dilemma, we contribute the first-of-its-kind fine-grained image quality assessment dataset for image restoration, termed <strong>FGRestore</strong>, comprising 18,408 restored images across six common IR tasks. Beyond conventional scalar quality scores, FGRestore was also annotated with 30,886 fine-grained pairwise preferences. Based on FGRestore, a comprehensive benchmark was conducted on the existing IQA metrics, which reveal significant inconsistencies between score-based IQA evaluations and the fine-grained restoration quality. Motivated by these findings, we further propose <strong>FGResQ</strong>, a new IQA model specifically designed for image restoration, which features both coarse-grained score regression and fine-grained quality ranking. Extensive experiments and comparisons demonstrate that FGResQ significantly outperforms state-of-the-art IQA metrics. Codes and model weights have been released in <a href="https://sxfly99.github.io/FGResQ-Homepage" target="_blank" rel="noopener noreferrer">https://sxfly99.github.io/FGResQ-Homepage</a>.
          </p>
          <section class="hero teaser">
            <div class="container is-max-desktop">
              <div class="hero-body">
                <img src="static/images/fig2_01.png" alt="FGResQ model architecture"/>
              </div>
            </div>
          </section>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Preliminary Validation Analysis Section -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 section-title">
          <span class="icon is-small"><i class="fas fa-chart-line"></i></span>
          <span>Preliminary Validation Analysis</span>
        </h2>
        <div class="content has-text-justified">
          <p>
            In image restoration tasks, both algorithm comparison and optimization frequently involve evaluating images with subtle quality differences. Algorithm comparison requires distinguishing between restoration results with marginal quality differences, while parameter optimization involves incremental quality changes that demand sensitive assessment methods to identify optimal configurations. To investigate whether existing IQA methods can objectively capture fine-grained quality differences in IR task, we conduct a comprehensive computational analysis on established IQA datasets. Specifically, we evaluate state-of-the-art IQA methods to assess their fine-grained discrimination capabilities.
          </p>
          <div style="overflow-x:auto; width:100%; margin-top:1.5em;">
            <p class="has-text-centered">Performance comparison across different MOS ranges on PIPAL dataset.</p>
            <table class="table is-bordered is-striped is-narrow is-hoverable is-fullwidth" style="font-size:0.85em; vertical-align:middle;">
              <thead>
                <tr>
                  <th>Type</th>
                  <th>Method</th>
                  <th>[0.0,0.2)<br>SRCC</th>
                  <th>[0.2,0.4)<br>SRCC</th>
                  <th>[0.4,0.6)<br>SRCC</th>
                  <th>[0.6,0.8)<br>SRCC</th>
                  <th>[0.8,1.0]<br>SRCC</th>
                  <th>Overall<br>SRCC</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td rowspan="4" style="vertical-align: middle;"><b>FR</b></td>
                  <td>PSNR</td><td>0.323</td><td>0.082</td><td>0.209</td><td>0.161</td><td>0.072</td><td>0.422</td>
                </tr>
                <tr>
                  <td>SSIM</td><td>0.293</td><td>0.108</td><td>0.258</td><td>0.254</td><td>0.049</td><td>0.530</td>
                </tr>
                <tr>
                  <td>LPIPS</td><td>-0.034</td><td>0.077</td><td>0.325</td><td>0.287</td><td>0.124</td><td>0.612</td>
                </tr>
                <tr>
                  <td>DISTS</td><td>0.168</td><td>0.159</td><td>0.310</td><td>0.242</td><td>0.165</td><td>0.585</td>
                </tr>
                <tr>
                  <td rowspan="10" style="vertical-align: middle;"><b>NR</b></td>
                  <td>NIQE</td><td>-0.126</td><td>-0.002</td><td>0.107</td><td>0.001</td><td>0.080</td><td>0.153</td>
                </tr>
                <tr>
                  <td>IL-NIQE</td><td>-0.235</td><td>-0.098</td><td>0.126</td><td>0.128</td><td>0.054</td><td>0.289</td>
                </tr>
                <tr>
                  <td>BRISQUE</td><td>-0.142</td><td>0.025</td><td>0.125</td><td>0.035</td><td>0.131</td><td>0.185</td>
                </tr>
                <tr>
                  <td>DB-CNN</td><td>-0157</td><td>0.321</td><td>0.353</td><td>0.330</td><td>-0.016</td><td>0.636</td>
                </tr>
                <tr>
                  <td>HyperIQA</td><td>0.100</td><td>0.274</td><td>0.314</td><td>0.292</td><td>0.032</td><td>0.584</td>
                </tr>
                <tr>
                  <td>MetaIQA</td><td>0.037</td><td>0.160</td><td>0.204</td><td>0.174</td><td>-0.101</td><td>0.423</td>
                </tr>
                <tr>
                  <td>LIQE</td><td>-0.232</td><td>0.053</td><td>0.175</td><td>0.299</td><td>0.107</td><td>0.479</td>
                </tr>
                <tr>
                  <td>CLIP-IQA</td><td>-0.152</td><td>0.211</td><td>0.238</td><td>0.293</td><td>0.071</td><td>0.530</td>
                </tr>
                <tr>
                  <td>Q-Align</td><td>0.230</td><td>0.301</td><td>0.337</td><td>0.213</td><td>0.178</td><td>0.418</td>
                </tr>
                <tr>
                  <td>DeQA-Score</td><td>0.568</td><td>0.676</td><td>0.623</td><td>0.516</td><td>0.350</td><td>0.747</td>
                </tr>
              </tbody>
            </table>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- FGResQ Section -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 section-title">
          <span class="icon is-small"><i class="fas fa-cubes"></i></span>
          <span>FGResQ</span>
        </h2>
        <div class="content has-text-justified">
          <p>
            Based on FGRestore, we propose FGResQ, a new fine-grained image quality assessment model for perceptual image restoration evaluation. FGResQ consists of two main components: (a) Degradation-aware Feature Learning that incorporates restoration task knowledge to enable unified evaluation across multiple IR tasks, and (b) Dual-branch Quality Prediction that simultaneously handles both coarse-grained score regression and fine-grained pairwise ranking.
          </p>
          <img src="static/images/FGResQ.png" alt="FGResQ Framework" style="max-width:100%; margin:2em auto; display:block;"/>
        </div>
      </div>
    </div>
  </div>
</section>


</section>
<!--End BibTex citation -->
  <!-- Performance Comparison Table -->
  <section class="section" id="Experiments">
    <div class="container is-max-desktop content" style="text-align:center;">
      <h2 class="title section-title" style="text-align:center;">
        <span class="icon is-small"><i class="fas fa-flask"></i></span>
        <span>Experiments</span>
      </h2>
      <p style="text-align:center;">Performance comparison on FGRestore dataset across different IR tasks. "-" indicates no reference images available.</p>
      <div style="overflow-x:auto; width:100%; text-align:center;">
        <table class="table is-bordered is-striped is-narrow is-hoverable is-fullwidth" style="font-size:0.85em; vertical-align:middle; min-width:1800px; margin-left:auto; margin-right:auto;">
    <thead>
      <tr>
        <th rowspan="2">Type</th>
        <th rowspan="2">Method</th>
        <th rowspan="2">Pub.</th>
        <th colspan="3">Deblurring</th>
        <th colspan="3">Denoising</th>
        <th colspan="3">Deraining</th>
        <th colspan="3">Dehazing</th>
        <th colspan="3">MixtureRestoration</th>
        <th colspan="3">SuperResolution</th>
        <th colspan="3">Average</th>
      </tr>
      <tr>
        <th>SRCC</th><th>PLCC</th><th>ACC</th>
        <th>SRCC</th><th>PLCC</th><th>ACC</th>
        <th>SRCC</th><th>PLCC</th><th>ACC</th>
        <th>SRCC</th><th>PLCC</th><th>ACC</th>
        <th>SRCC</th><th>PLCC</th><th>ACC</th>
        <th>SRCC</th><th>PLCC</th><th>ACC</th>
        <th>SRCC</th><th>PLCC</th><th>ACC</th>
      </tr>
    </thead>
    <tbody>
      <tr><td rowspan="5" style="vertical-align: middle;"><b>FR</b></td><td>PSNR</td><td>-</td><td>0.187</td><td>0.167</td><td>0.634</td><td>0.487</td><td>0.482</td><td>0.775</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>0.280</td><td>0.248</td><td>0.643</td><td>0.296</td><td>0.303</td><td>0.624</td><td>0.313</td><td>0.300</td><td>0.669</td></tr>
      <tr><td>SSIM</td><td>TIP'04</td><td>0.441</td><td>0.348</td><td>0.695</td><td>0.642</td><td>0.652</td><td><b>0.789</b></td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>0.421</td><td>0.379</td><td>0.684</td><td>0.351</td><td>0.361</td><td>0.641</td><td>0.464</td><td>0.435</td><td>0.702</td></tr>
      <tr><td>LPIPS</td><td>CVPR'18</td><td>0.776</td><td>0.700</td><td>0.755</td><td>0.673</td><td>0.680</td><td>0.765</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>0.466</td><td>0.475</td><td>0.658</td><td>0.448</td><td>0.460</td><td>0.666</td><td>0.591</td><td>0.579</td><td>0.711</td></tr>
      <tr><td>DISTS</td><td>TPAMI'20</td><td><u>0.907</u></td><td><u>0.901</u></td><td>0.845</td><td>0.679</td><td>0.672</td><td>0.739</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>0.495</td><td>0.464</td><td>0.644</td><td>0.482</td><td>0.488</td><td>0.658</td><td>0.640</td><td>0.631</td><td>0.721</td></tr>
      <tr><td>A-FINE</td><td>CVPR'25</td><td><u>0.907</u></td><td>0.796</td><td><u>0.865</u></td><td>0.624</td><td>0.620</td><td>0.747</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>0.536</td><td>0.528</td><td>0.645</td><td>0.421</td><td>0.434</td><td>0.688</td><td>0.622</td><td>0.594</td><td><u>0.736</u></td></tr>
      <tr><td rowspan="9" style="vertical-align: middle;"><b>NR</b></td><td>NIQE</td><td>SPL'12</td><td>0.382</td><td>0.410</td><td>0.529</td><td>0.240</td><td>0.151</td><td>0.564</td><td>0.030</td><td>0.057</td><td>0.694</td><td>0.036</td><td>0.063</td><td>0.446</td><td>0.041</td><td>0.027</td><td>0.541</td><td>0.176</td><td>0.072</td><td>0.503</td><td>0.151</td><td>0.130</td><td>0.546</td></tr>
      <tr><td>BRISQUE</td><td>TIP'12</td><td>0.354</td><td>0.354</td><td>0.555</td><td>0.254</td><td>0.114</td><td>0.569</td><td>0.112</td><td>0.102</td><td>0.603</td><td>0.132</td><td>0.088</td><td>0.436</td><td>0.201</td><td>0.064</td><td>0.575</td><td>0.142</td><td>0.040</td><td>0.514</td><td>0.199</td><td>0.127</td><td>0.542</td></tr>
      <tr><td>DB-CNN</td><td>TCSVT'22</td><td>0.788</td><td>0.786</td><td>0.688</td><td>0.478</td><td>0.431</td><td>0.611</td><td>0.243</td><td>0.259</td><td>0.437</td><td>0.643</td><td>0.645</td><td>0.524</td><td>0.415</td><td>0.460</td><td>0.614</td><td>0.459</td><td>0.454</td><td>0.643</td><td>0.504</td><td>0.506</td><td>0.586</td></tr>
      <tr><td>HyperIQA</td><td>CVPR'25</td><td>0.871</td><td>0.887</td><td>0.402</td><td>0.605</td><td>0.625</td><td>0.675</td><td>0.264</td><td>0.294</td><td>0.484</td><td>0.643</td><td>0.674</td><td>0.409</td><td>0.523</td><td>0.535</td><td>0.499</td><td>0.437</td><td>0.433</td><td>0.538</td><td>0.557</td><td>0.574</td><td>0.501</td></tr>
      <tr><td>CLIP-IQA</td><td>AAAI'23</td><td>0.867</td><td>0.785</td><td>0.765</td><td>0.474</td><td>0.440</td><td>0.625</td><td>0.241</td><td>0.221</td><td>0.349</td><td>0.547</td><td>0.499</td><td>0.546</td><td>0.302</td><td>0.300</td><td>0.580</td><td>0.244</td><td>0.186</td><td>0.571</td><td>0.446</td><td>0.405</td><td>0.573</td></tr>
      <tr><td>Q-Align</td><td>ICML'24</td><td>0.767</td><td>0.804</td><td>0.795</td><td>0.676</td><td>0.687</td><td>0.731</td><td>0.433</td><td>0.421</td><td>0.455</td><td>0.715</td><td>0.765</td><td>0.584</td><td>0.569</td><td>0.571</td><td>0.658</td><td>0.376</td><td>0.366</td><td>0.662</td><td>0.589</td><td>0.603</td><td>0.648</td></tr>
      <tr><td>DeQA-Score</td><td>CVPR'25</td><td>0.815</td><td>0.843</td><td>0.819</td><td><u>0.754</u></td><td><u>0.771</u></td><td><u>0.778</u></td><td><b>0.507</b></td><td><b>0.576</b></td><td>0.426</td><td><u>0.762</u></td><td><u>0.803</u></td><td><u>0.644</u></td><td><u>0.669</u></td><td><u>0.679</u></td><td><u>0.697</u></td><td><b>0.561</b></td><td><b>0.573</b></td><td><u>0.718</u></td><td><u>0.678</u></td><td><u>0.707</u></td><td>0.680</td></tr>
      <tr><td>Compare2Score</td><td>NeurIPS'24</td><td>0.769</td><td>0.813</td><td>0.757</td><td>0.661</td><td>0.679</td><td>0.687</td><td>0.074</td><td>0.108</td><td><b>0.790</b></td><td>0.334</td><td>0.381</td><td>0.436</td><td>0.494</td><td>0.519</td><td>0.635</td><td>0.317</td><td>0.315</td><td>0.607</td><td>0.441</td><td>0.469</td><td>0.652</td></tr>
      <tr><td><b>FGResQ</b></td><td>AAAI'26</td><td><b>0.926</b></td><td><b>0.910</b></td><td><b>0.873</b></td><td><b>0.759</b></td><td><b>0.777</b></td><td>0.760</td><td><u>0.496</u></td><td><u>0.518</u></td><td><u>0.778</u></td><td><b>0.821</b></td><td><b>0.854</b></td><td><b>0.669</b></td><td><b>0.698</b></td><td><b>0.706</b></td><td><b>0.713</b></td><td><u>0.521</u></td><td><u>0.536</u></td><td><b>0.721</b></td><td><b>0.703</b></td><td><b>0.717</b></td><td><b>0.752</b></td></tr>
    </tbody>
  </table>
  <p style="font-size:0.85em; margin-top:0.5em;">Underline indicates runner-up, bold indicates best.</p>
    </div>
  </section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered section-title">
      <span class="icon is-small"><i class="fas fa-images"></i></span>
      <span>Fine-grained Examples</span>
    </h2>
    <div class="carousel-container" style="max-width: 720px; margin: auto;">
      <div id="carousel-fine-grained" class="carousel">
        <div class="item">
          <p class="has-text-centered fg-label deblur">
            <span class="icon is-small"><i class="fas fa-broom"></i></span> Deblurring
          </p>
          <img class="fg-image" src="static/sup_figs/example_deblur_01.png" alt="Deblur Example">
        </div>
        <div class="item">
          <p class="has-text-centered fg-label dehaze">
            <span class="icon is-small"><i class="fas fa-cloud"></i></span> Dehazing
          </p>
          <img class="fg-image" src="static/sup_figs/example_dehazing_01.png" alt="Dehazing Example">
        </div>
        <div class="item">
          <p class="has-text-centered fg-label denoise">
            <span class="icon is-small"><i class="fas fa-sliders-h"></i></span> Denoising
          </p>
          <img class="fg-image" src="static/sup_figs/example_denoise_01.png" alt="Denoise Example">
        </div>
        <div class="item">
          <p class="has-text-centered fg-label derain">
            <span class="icon is-small"><i class="fas fa-umbrella"></i></span> Deraining
          </p>
          <img class="fg-image" src="static/sup_figs/example_derain_01.png" alt="Derain Example">
        </div>
        <div class="item">
          <p class="has-text-centered fg-label mix">
            <span class="icon is-small"><i class="fas fa-layer-group"></i></span> Mixture Restoration
          </p>
          <img class="fg-image" src="static/sup_figs/example_mix_01.png" alt="Mix Restoration Example">
        </div>
        <div class="item">
          <p class="has-text-centered fg-label sr">
            <span class="icon is-small"><i class="fas fa-search-plus"></i></span> Super-Resolution
          </p>
          <img class="fg-image" src="static/sup_figs/example_sr_01.png" alt="Super Resolution Example">
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Qualitative Analysis -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered section-title">
      <span class="icon is-small"><i class="fas fa-eye"></i></span>
      <span>Qualitative Analysis</span>
    </h2>
    <div class="carousel-container" style="max-width: 720px; margin: auto;">
      <div id="carousel-qualitative" class="carousel">
        <div class="item">
          <p class="has-text-centered fg-label deblur">
            <span class="icon is-small"><i class="fas fa-broom"></i></span> Deblurring
          </p>
          <img class="fg-image" src="static/sup_figs/quanli_deblur_01.png" alt="Deblur Qualitative">
        </div>
        <div class="item">
          <p class="has-text-centered fg-label dehaze">
            <span class="icon is-small"><i class="fas fa-cloud"></i></span> Dehazing
          </p>
          <img class="fg-image" src="static/sup_figs/quanli_dehaze_01.png" alt="Dehaze Qualitative">
        </div>
        <div class="item">
          <p class="has-text-centered fg-label denoise">
            <span class="icon is-small"><i class="fas fa-sliders-h"></i></span> Denoising
          </p>
          <img class="fg-image" src="static/sup_figs/quanli_denoise_01.png" alt="Denoise Qualitative">
        </div>
        <div class="item">
          <p class="has-text-centered fg-label derain">
            <span class="icon is-small"><i class="fas fa-umbrella"></i></span> Deraining
          </p>
          <img class="fg-image" src="static/sup_figs/quanli_derain_01.png" alt="Derain Qualitative">
        </div>
        <div class="item">
          <p class="has-text-centered fg-label mix">
            <span class="icon is-small"><i class="fas fa-layer-group"></i></span> Mixture Restoration
          </p>
          <img class="fg-image" src="static/sup_figs/quanli_mix_01.png" alt="Mix Restoration Qualitative">
        </div>
        <div class="item">
          <p class="has-text-centered fg-label sr">
            <span class="icon is-small"><i class="fas fa-search-plus"></i></span> Super-Resolution
          </p>
          <img class="fg-image" src="static/sup_figs/quanli_sr_01.png" alt="Super Resolution Qualitative">
        </div>
      </div>
    </div>
  </div>
</section>


<!--BibTex citation -->
  <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title section-title">
      <span class="icon is-small"><i class="fas fa-book"></i></span>
      <span>BibTeX</span>
    </h2>

    <div class="bibtex-card">
      <button id="bibtex-copy-btn" class="button is-small btn-copy" type="button" title="Copy BibTeX">
        <span class="icon"><i class="fas fa-copy"></i></span>
        <span>Copy</span>
      </button>

      <pre><code id="bibtex-code">
@article{sheng2025fgresq,
  title={Fine-grained Image Quality Assessment for Perceptual Image Restoration},
  author={Sheng, Xiangfei and Pan, Xiaofeng and Yang, Zhichao and Chen, Pengfei and Li, Leida},
  journal={arXiv preprint arXiv:2508.14475},
  year={2025}
}
      </code></pre>
    </div>
  </div>
</section>

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
